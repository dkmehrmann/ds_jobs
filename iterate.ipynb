{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scrapy import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Glassdoor\n",
    "Iterates through glassdoor pages to get links to Data Science Jobs in Chicago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulling links from page 1\n",
      "pulling links from page 2\n",
      "Got 24 links from page 2\n",
      "pulling links from page 3\n",
      "Got 16 links from page 3\n",
      "pulling links from page 4\n",
      "Got 19 links from page 4\n",
      "pulling links from page 5\n",
      "Got 0 links from page 5\n",
      "pulling links from page 6\n",
      "Got 0 links from page 6\n",
      "pulling links from page 7\n",
      "Got 0 links from page 7\n",
      "pulling links from page 8\n",
      "Got 0 links from page 8\n",
      "pulling links from page 9\n",
      "Got 0 links from page 9\n",
      "pulling links from page 10\n",
      "Got 0 links from page 10\n"
     ]
    }
   ],
   "source": [
    "gd_p1 = 'http://www.glassdoor.com/Job/chicago-data-scientist-jobs-SRCH_IL.0,7_IC1128808_KO8,22.htm'\n",
    "gd_links = []\n",
    "gd_ids = []\n",
    "n_pages = 10\n",
    "\n",
    "for i in range(1,n_pages + 1):\n",
    "    print('pulling links from page {0}'.format(i))\n",
    "    if i == 1:\n",
    "        gd_links, gd_ids = get_gd_links(get_soup(gd_p1))\n",
    "        print('Got {0} links from page {1}'.format(len(gd_links),i))\n",
    "    else:\n",
    "        gd_url = 'http://www.glassdoor.com/Job/chicago-data-scientist-jobs-SRCH_IL.0,7_IC1128808_KO8,22_IP{0}.htm'.format(i)\n",
    "        links, ids = get_gd_links(get_soup(gd_url), gd_ids)\n",
    "        gd_links.extend(links)\n",
    "        gd_ids.extend(ids)\n",
    "        print('Got {0} links from page {1}'.format(len(links),i))\n",
    "    time.sleep(5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gd_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle\n",
    "Iterates through Kaggle Forums to get links to Data Science Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulling links from page 1\n",
      "pulling links from page 2\n",
      "Got 20 links from page 2\n",
      "pulling links from page 3\n",
      "Got 20 links from page 3\n",
      "pulling links from page 4\n",
      "Got 20 links from page 4\n",
      "pulling links from page 5\n",
      "Got 20 links from page 5\n",
      "pulling links from page 6\n",
      "Got 20 links from page 6\n",
      "pulling links from page 7\n",
      "Got 20 links from page 7\n",
      "pulling links from page 8\n",
      "Got 20 links from page 8\n",
      "pulling links from page 9\n",
      "Got 20 links from page 9\n",
      "pulling links from page 10\n",
      "Got 20 links from page 10\n"
     ]
    }
   ],
   "source": [
    "kg_p1 = 'https://www.kaggle.com/forums/f/145/data-science-jobs'\n",
    "kg_links = []\n",
    "kg_ids = []\n",
    "n_pages = 10\n",
    "\n",
    "for i in range(1,n_pages + 1):\n",
    "    print('pulling links from page {0}'.format(i))\n",
    "    if i == 1:\n",
    "        kg_links, kg_ids = get_kg_links(get_soup(kg_p1))\n",
    "        print('Got {0} links from page {1}'.format(len(kg_links),i))\n",
    "    else:\n",
    "        kg_url = 'https://www.kaggle.com/forums/f/145/data-science-jobs?page={0}'.format(i)\n",
    "        links, ids = get_kg_links(get_soup(kg_url), kg_ids)\n",
    "        kg_links.extend(links)\n",
    "        kg_ids.extend(ids)\n",
    "        print('Got {0} links from page {1}'.format(len(links),i))\n",
    "    time.sleep(5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kg_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###LinkedIn\n",
    "Iterates through LinkedIn to get Data Science jobs in Chicago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulling links from page 1\n",
      "Got 0 links from page 1\n",
      "pulling links from page 2\n",
      "Got 0 links from page 2\n",
      "pulling links from page 3\n",
      "Got 21 links from page 3\n",
      "pulling links from page 4\n",
      "Got 25 links from page 4\n",
      "pulling links from page 5\n",
      "Got 23 links from page 5\n",
      "pulling links from page 6\n",
      "Got 22 links from page 6\n",
      "pulling links from page 7\n",
      "Got 24 links from page 7\n",
      "pulling links from page 8\n",
      "Got 21 links from page 8\n",
      "pulling links from page 9\n",
      "Got 12 links from page 9\n",
      "pulling links from page 10\n",
      "Got 13 links from page 10\n"
     ]
    }
   ],
   "source": [
    "li_p1 = 'https://www.linkedin.com/job/data-scientist-jobs-chicago-il/?sort=relevance&page_num=1&trk=jserp_pagination_1'\n",
    "\n",
    "li_links = []\n",
    "li_ids = []\n",
    "n_pages = 10\n",
    "\n",
    "for i in range(1,n_pages + 1):\n",
    "    print('pulling links from page {0}'.format(i))\n",
    "    if i == 1:\n",
    "        li_links, li_ids = get_li_links(get_soup(li_p1))\n",
    "        print('Got {0} links from page {1}'.format(len(li_links),i))\n",
    "    else:\n",
    "        li_url = 'https://www.linkedin.com/job/data-scientist-jobs-chicago-il/?sort=relevance&page_num={0}&trk=jserp_pagination_{0}'.format(i)\n",
    "        links, ids = get_li_links(get_soup(li_url), li_ids)\n",
    "        li_links.extend(links)\n",
    "        li_ids.extend(ids)\n",
    "        print('Got {0} links from page {1}'.format(len(links),i))\n",
    "    time.sleep(5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(li_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crawl_gd(n_pages=5,sleep_timer=10):\n",
    "    \n",
    "    gd_p1 = 'http://www.glassdoor.com/Job/chicago-data-scientist-jobs-SRCH_IL.0,7_IC1128808_KO8,22.htm'\n",
    "    gd_links = []\n",
    "    gd_ids = []\n",
    "\n",
    "    for i in range(1,n_pages + 1):\n",
    "        print('pulling links from page {0}'.format(i))\n",
    "        if i == 1:\n",
    "            gd_links, gd_ids = get_gd_links(get_soup(gd_p1))\n",
    "            print('Got {0} links from page {1}'.format(len(gd_links),i))\n",
    "        else:\n",
    "            gd_url = 'http://www.glassdoor.com/Job/chicago-data-scientist-jobs-SRCH_IL.0,7_IC1128808_KO8,22_IP{0}.htm'.format(i)\n",
    "            links, ids = get_gd_links(get_soup(gd_url), gd_ids)\n",
    "            gd_links.extend(links)\n",
    "            gd_ids.extend(ids)\n",
    "            print('Got {0} links from page {1}'.format(len(links),i))\n",
    "        time.sleep(sleep_timer)\n",
    "        \n",
    "    return gd_links\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def crawl_kg(n_pages = 10, sleep_timer=10):\n",
    "    \n",
    "    kg_p1 = 'https://www.kaggle.com/forums/f/145/data-science-jobs'\n",
    "    kg_links = []\n",
    "    kg_ids = []\n",
    "\n",
    "    for i in range(1,n_pages + 1):\n",
    "        print('pulling links from page {0}'.format(i))\n",
    "        if i == 1:\n",
    "            kg_links, kg_ids = get_kg_links(get_soup(kg_p1))\n",
    "            print('Got {0} links from page {1}'.format(len(kg_links),i))\n",
    "        else:\n",
    "            kg_url = 'https://www.kaggle.com/forums/f/145/data-science-jobs?page={0}'.format(i)\n",
    "            links, ids = get_kg_links(get_soup(kg_url), kg_ids)\n",
    "            kg_links.extend(links)\n",
    "            kg_ids.extend(ids)\n",
    "            print('Got {0} links from page {1}'.format(len(links),i))\n",
    "        time.sleep(sleep_timer)\n",
    "        \n",
    "    return kg_links\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def crawl_li(n_pages = 10, sleep_timer=10):\n",
    "    \n",
    "    li_p1 = 'https://www.linkedin.com/job/data-scientist-jobs-chicago-il/?sort=relevance&page_num=1&trk=jserp_pagination_1'\n",
    "    li_links = []\n",
    "    li_ids = []\n",
    "\n",
    "    for i in range(1,n_pages + 1):\n",
    "        print('pulling links from page {0}'.format(i))\n",
    "        if i == 1:\n",
    "            li_links, li_ids = get_li_links(get_soup(li_p1))\n",
    "            print('Got {0} links from page {1}'.format(len(li_links),i))\n",
    "        else:\n",
    "            li_url = 'https://www.linkedin.com/job/data-scientist-jobs-chicago-il/?sort=relevance&page_num={0}&trk=jserp_pagination_{0}'.format(i)\n",
    "            links, ids = get_li_links(get_soup(li_url), li_ids)\n",
    "            li_links.extend(links)\n",
    "            li_ids.extend(ids)\n",
    "            print('Got {0} links from page {1}'.format(len(links),i))\n",
    "        time.sleep(sleep_timer)\n",
    "        \n",
    "    return li_links"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
