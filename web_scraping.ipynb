{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping - Data Science Jobs in Chicago, IL\n",
    "### Query: Data Scientist -- Chicago, IL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Glassdoor\n",
    "Glassdoor also has a [free public API](http://www.glassdoor.com/developer/index.htm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uri = 'http://www.glassdoor.com'\n",
    "p1 = 'http://www.glassdoor.com/Job/chicago-data-scientist-jobs-SRCH_IL.0,7_IC1128808_KO8,22.htm'\n",
    "p2 = 'http://www.glassdoor.com/Job/chicago-data-scientist-jobs-SRCH_IL.0,7_IC1128808_KO8,22_IP2.htm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set a regex to find the job id's from a URL\n",
    "regex = r'ListingId=(.*)'\n",
    "# this is the page we are working on\n",
    "# later, we will iterate through multiple pages\n",
    "page = requests.get(p1,headers={'User-Agent': 'Mozilla/5.0'})\n",
    "\n",
    "# get the data and the soup from the page\n",
    "data = page.text\n",
    "soup = BeautifulSoup(data)\n",
    "\n",
    "# initialize empty lists \n",
    "jobs = []\n",
    "job_ids = []\n",
    "\n",
    "for link in soup.find_all('a'):                                 # for each link in the page\n",
    "    href = link.get('href')                                     # get the href\n",
    "    if href:                                                    # if the href exists\n",
    "        if ('partner/job' in href and                           # if it is a link for a job posting\n",
    "            re.search(regex, href).group(1) not in job_ids):    # and we don't alread have that job\n",
    "            jobs.append(uri + href)                             # add the job to the list of jobs\n",
    "            job_ids.append(re.search(regex, href).group(1))     # add the job id to the list of job ids\n",
    "            \n",
    "            \n",
    "# jobs has the links to the jobs on the page\n",
    "# job_ids was an intermediate list to check if we haven't seen that job yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the number of jobs on the page\n",
    "len(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p1 = 'http://www.indeed.com/jobs?q=Data+Scientist&l=Chicago%2C+IL'\n",
    "p2 = 'http://www.indeed.com/jobs?q=Data+Scientist&l=Chicago%2C+IL&start=10'\n",
    "p3 = 'http://www.indeed.com/jobs?q=Data+Scientist&l=Chicago%2C+IL&start=20'\n",
    "uri = 'http://www.indeed.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "page = requests.get(p1, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "data = page.text\n",
    "soup = BeautifulSoup(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jobs = []\n",
    "for link in soup.find_all('a'):\n",
    "    if 'rc' in link.get('href'): # there is an 'rc' in the links for the jobs\n",
    "        jobs.append(uri + link.get('href')) # links to the actual jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.indeed.com/rc/clk?jk=265ad4a82eb14f2d'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it appears that the job postings are external links, which isn't good for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p1 = 'https://www.kaggle.com/forums/f/145/data-science-jobs'\n",
    "p2 = 'https://www.kaggle.com/forums/f/145/data-science-jobs?page=2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page = requests.get(p1, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "data = page.text\n",
    "soup = BeautifulSoup(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
